{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRAISE THE LORD ALMIGHTY FATHER Thank You JESUS Praise You JESUS Forever May the HOLY SPIRIT Guide Us MOTHER MARY PRAY For Us SAINT JOSEPH, PRAY For Us SAINT ANTHONY PRAY For Us GOD BLESS !!! ‚õ™üß°‚úùüß°‚õ™\n"
     ]
    }
   ],
   "source": [
    "print(\"PRAISE THE LORD ALMIGHTY FATHER Thank You JESUS Praise You JESUS Forever May the HOLY SPIRIT Guide Us MOTHER MARY PRAY For Us SAINT JOSEPH, PRAY For Us SAINT ANTHONY PRAY For Us GOD BLESS !!! ‚õ™üß°‚úùüß°‚õ™\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creted for Random Code Testing "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 2s 7ms/step - loss: 0.1304 - val_loss: 0.1009\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.1023 - val_loss: 0.0978\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0949 - val_loss: 0.0913\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0915 - val_loss: 0.0894\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0890 - val_loss: 0.0874\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0879 - val_loss: 0.0854\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0863 - val_loss: 0.0844\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0858 - val_loss: 0.0838\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0859 - val_loss: 0.0843\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0855 - val_loss: 0.0838\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0856 - val_loss: 0.0838\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0848 - val_loss: 0.0838\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0842 - val_loss: 0.0838\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0842 - val_loss: 0.0839\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0844 - val_loss: 0.0840\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0840 - val_loss: 0.0837\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0835 - val_loss: 0.0839\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0839 - val_loss: 0.0839\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0836 - val_loss: 0.0839\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0835 - val_loss: 0.0839\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0835 - val_loss: 0.0840\n",
      "313/313 [==============================] - 1s 1ms/step\n",
      "[[0.4734202 ]\n",
      " [0.48627636]\n",
      " [0.4824555 ]\n",
      " ...\n",
      " [0.46986634]\n",
      " [0.47539932]\n",
      " [0.47820204]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "\n",
    "# Create the ANN model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(51,), activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))  # Output layer with 1 neuron for regression\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model with early stopping\n",
    "model.fit(X_train_ann, y_train_ann, epochs=50, batch_size=64, validation_data=(X_test_ann, y_test_ann), callbacks=[early_stopping])\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Print the predicted values\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
